---
# - name: Set Elastic servers hosts file
#   template:
#     src: hosts_file.j2
#     dest: /etc/hosts

# - name: Register Debian destribution
#   shell: lsb_release -cs
#   register: lsb_release
#   when: ansible_os_family == "Debian"

# - name: Register Debian arhitecture
#   shell: dpkg --print-architecture
#   register: arch
#   when: ansible_os_family == "Debian"

# - name: Install additional packages
#   package:
#     name:
#       - python3-pip
#     state: latest

# - name: Remove docker if already exist
#   apt:
#     name: "{{ item }}"
#     state: absent
#   loop:
#     - 'docker-ce'
#     - 'docker-ce-cli'
#     - 'docker-scan-plugin'
#     - 'docker'

# - name: Remove docker files if they exist
#   file:
#     name: "{{ item }}"
#     state: absent
#   loop:
#     - '/var/lib/docker'
#     - '/var/run/docker.sock'
#     - '/usr/bin/docker-compose'

# - name: Remove podman packages if already installed
#   apt:
#     name: "podman*"
#     state: absent
#   ignore_errors: True

# - name: Delete containers directory
#   file:
#     path: /var/containers
#     state: absent

# # Reboot after Docker is removed.
# - name: Reboot host
#   reboot:
#     connect_timeout: "{{ reboot_connect_timeout }}"
#     post_reboot_delay: "{{ reboot_post_reboot_delay }}"
#     reboot_timeout: "{{ reboot_timeout }}"

# # Docker/Podman
# - name: Install container engine
#   block:
#     - name: Install docker
#       when: ansible_facts['distribution_version'] is version('22.04', '<=')
#       block:
#         - name: Add an apt docker signing key
#           ansible.builtin.apt_key:
#             url: https://download.docker.com/linux/ubuntu/gpg
#             state: present
#             keyring: /usr/share/keyrings/docker-archive-keyring.gpg

#         - name: Add specified repository into sources list
#           ansible.builtin.apt_repository:
#             repo: "deb [arch={{ arch.stdout }} signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu {{ lsb_release.stdout }} stable"
#             state: present
#             filename: docker

#         - name: Create docker configuration directory
#           file:
#             path: /etc/docker
#             state: directory
#             mode: '0700'

#         - name: Create docker containers directory
#           file:
#             path: /var/containers
#             state: directory
#             mode: '0700'

#         - name: Creat docker log directory
#           file:
#             path: /var/log/docker
#             state: directory
#             owner: syslog
#             group: adm
#             mode: '0700'

#         - name: Copy docker related configuration files
#           copy:
#             src: "{{ item.src }}"
#             dest: "/etc/{{ item.dest }}"
#             owner: root
#             group: root
#             mode: '0644'
#           loop:
#             - { src: 'docker/daemon.json', dest: 'docker/daemon.json' }
#             - { src: 'docker/docker-logrotate.conf', dest: 'logrotate.d/docker.conf' }
#             - { src: 'docker/docker-rsyslog.conf', dest: 'rsyslog.d/10-docker.conf' }
        
#         - name: Install and upgrade pip
#           pip:
#             name:
#               - docker=={{ pip_docker_version }}
#               - docker-compose=={{ pip_docker_compose_version }}
#             executable: pip3
        
#         - name: Install docker-compose
#           get_url:
#             url: "https://github.com/docker/compose/releases/download/{{ docker_compose_version }}/docker-compose-linux-x86_64"
#             dest: /usr/bin/docker-compose
#             mode: '0744'

#         - name: Install docker packages
#           apt:
#             name: "{{ docker_ce_version }}"
#             state: present
#             update_cache: yes

#         - name: Get running containers
#           docker_host_info:
#             containers: yes
#           register: docker_info

#         - name: Destroy stopped containers
#           docker_container:
#             name: "{{ item }}"
#             state: absent
#           loop: "{{ docker_info.containers | map(attribute='Id') | list }}"

#     - name: Install podman
#       when: ansible_facts['distribution_version'] is version('22.04', '>')
#       block:
#         - name: Install podman package
#           apt:
#             name: podman
#             state: present
#             update_cache: yes
    
# # Reboot after Docker is removed.
# - name: Reboot host
#   reboot:
#     connect_timeout: "{{ reboot_connect_timeout }}"
#     post_reboot_delay: "{{ reboot_post_reboot_delay }}"
#     reboot_timeout: "{{ reboot_timeout }}"

# #Tuning
# # ES specific req.
# - name: vm.max_map_count on all nodes
#   ansible.posix.sysctl:
#     name: vm.max_map_count
#     value: '262144'
#     sysctl_set: yes
#     state: present
#     reload: yes

# # Do less swapping sysctl kernel parameters
# - name: vm.swappiness
#   ansible.posix.sysctl:
#     name: vm.swappiness
#     value: '10'
#     sysctl_set: yes
#     state: present
#     reload: yes

# - name: vm.dirty_ratio
#   ansible.posix.sysctl:
#     name: vm.dirty_ratio
#     value: '60'
#     sysctl_set: yes
#     state: present
#     reload: yes

# - name: vm.dirty_background_ratio
#   ansible.posix.sysctl:
#     name: vm.dirty_background_ratio
#     value: '2'
#     sysctl_set: yes
#     state: present
#     reload: yes
 
# # Increase number of incoming connections
# - name: net.core.somaxconn
#   ansible.posix.sysctl:
#     name: net.core.somaxconn
#     value: '65536'
#     sysctl_set: yes
#     state: present
#     reload: yes

# # Improved congestion control - network stack
# - name: net.core.default_qdisc
#   ansible.posix.sysctl:
#     name: net.core.default_qdisc
#     value: 'fq'
#     sysctl_set: yes
#     state: present
#     reload: yes

# - name: net.ipv4.tcp_congestion_control
#   ansible.posix.sysctl:
#     name: net.ipv4.tcp_congestion_control
#     value: 'bbr'
#     sysctl_set: yes
#     state: present
#     reload: yes    

#Create RSA on elastic[0] and copy the public key to the rest of the nodes in the cluster, kibana and so on
- name: Create RSA
  block:
    - name: Create rsa
      community.crypto.openssh_keypair:
        path: /root/.ssh/logging_id_ssh_rsa
        comment: "key for cross server communication from main node"
      when: inventory_hostname in groups['logging_cluster'][0] 

    - name: Register the public key
      shell: cat /root/.ssh/logging_id_ssh_rsa.pub
      register: logging_pub
      delegate_to: "{{ groups['logging_cluster'] | sort | first }}"
      run_once: true
    
    - name: Copy the pub key to other nodes
      authorized_key:
        user: root
        state: present
        key: "{{ logging_pub.stdout }}"
      when: inventory_hostname is in groups['logging_cluster'][0:]

#Files
- name: Create logging directory if it does not exist
  ansible.builtin.file:
    path: "{{ item }}"
    state: directory
    mode: '0755'
  with_items:
    - /var/containers/logging
    - /var/containers/logging/extra

- name: Copy logging config files
  ansible.builtin.template:
    src: "docker-compose.j2"
    dest: "/var/containers/docker-compose.yml"
    owner: root
    group: root
    mode: u=rw,g=rw,o=r
  tags: cert

- name: Copy logging certs files
  ansible.builtin.template:
    src: "{{ item }}.j2"
    dest: "/var/containers/logging/extra/{{ item }}.yml"
    owner: root
    group: root
    mode: u=rw,g=rw,o=r
  loop:
    - create-certs
    - env
    - instances
  when: inventory_hostname in groups['logging_cluster'][0]

- name: Delete existing logging services if exist
  community.docker.docker_compose:
    project_src: /var/containers
    state: absent

#Clean existing data if exists
- name: Delete elasticsearch volumes
  file: 
    state: absent
    path: "{{ item }}"
  loop:
    - "{{ volume_certs }}"
    - "{{ volume_data }}"

#Create directories for docker containers
- name: Create elasticsearch directories
  file: 
    state: directory
    path: "{{ item }}"
    mode: g=rwx
    owner: 1000
    group: 0
  loop:
    - "{{ volume_certs }}"
    - "{{ volume_data }}"

- name: Copy certificates and key from the ansible-vault
  copy:
    content: "{{ item.content }}"
    dest: "{{ volume_certs }}/{{ item.name }}"
    owner: root
    group: root
    mode: "u=rw,g=r,o="
  loop:
    - "{{ tino_certificate }}"
    - "{{ tino_root_certificate }}"
    - "{{ tino_entity_certificate }}"
    - "{{ tino_certificate_key }}"

#Rsync certs folder to other nodes
- name: Rsync certs to other nodes
  ansible.builtin.synchronize:
    src: "{{ volume_certs }}"
    dest: "{{ volume_certs }}"
    private_key: ~/.ssh/logging_id_ssh_rsa
  delegate_to: "{{ groups['logging_cluster'] | sort | first }}"
  when: inventory_hostname is not in groups['logging_cluster'][0]

#Setting up password on the first elastic node
- name: Make sure elastic_password is only set first elastic host
  ansible.builtin.lineinfile:
    path: /var/containers/docker-compose.yml
    state: absent
    regexp: 'ELASTIC_PASSWORD'
  when: inventory_hostname in groups['logging_cluster'] and inventory_hostname != groups['logging_cluster'][0]

- name: Create and start logging elasticsearch services
  community.docker.docker_compose:
    project_src: /var/containers
    services:
      - elasticsearch
      - node-exporter
      - cadvisor

- name: Wait for port 9200 to become open on the host, don't start checking for 20 seconds
  wait_for:
    port: 9200
    delay: 20
  when: inventory_hostname in groups['logging_cluster'][0]
